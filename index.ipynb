{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a87c5e",
   "metadata": {},
   "source": [
    "# Random Forest Classifier in PySpark - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7260babc",
   "metadata": {},
   "source": [
    "## Introduction  \n",
    "\n",
    "In this lab, you will build a Random Forest Classifier model to study the ecommerce behavior of consumers from a multi-category store. First, you will need to download the data to your local machine, then you will load the data from the local machine onto a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe626fb",
   "metadata": {},
   "source": [
    "## Objectives  \n",
    "\n",
    "* Use the kaggle eCommerce dataset in PySpark\n",
    "* Build and train a random forest classifier in PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f97f0",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "* Accept the Kaggle policy and download the data from [Kaggle](https://www.kaggle.com/code/tshephisho/ecommerce-behaviour-using-xgboost/data)\n",
    "* For the first model you will only use the 2019-Nov csv data (which is still around ~2gb zipped)\n",
    "* You will run this notebook in a new `pyspark-env` environment following [these setup instructions without docker](https://github.com/learn-co-curriculum/dsc-spark-docker-installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9959b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata (18 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ---------------------------------------- 0.0/247.7 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/247.7 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 41.0/247.7 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------  245.8/247.7 kB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 247.7/247.7 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting numpy>=1.20.3 (from pandas)\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.8 MB 8.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/10.8 MB 8.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/10.8 MB 7.6 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/10.8 MB 7.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/10.8 MB 7.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.1/10.8 MB 7.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.6/10.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.0/10.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.3/10.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.7/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.1/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.4/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.8/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.1/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.4/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.9/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.6/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.0/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.2/10.8 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.5/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.1/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.5/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.4/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/10.8 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/14.9 MB 9.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.9/14.9 MB 8.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.4/14.9 MB 8.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.7/14.9 MB 8.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.0/14.9 MB 8.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 3.0/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.2/14.9 MB 8.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.6/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.0/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.3/14.9 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.2/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.6/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.9/14.9 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.2/14.9 MB 7.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.6/14.9 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.1/14.9 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.4/14.9 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.8/14.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.2/14.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.8/14.9 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.3/14.9 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.7/14.9 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.1/14.9 MB 7.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.4/14.9 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.8/14.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.2/14.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.6/14.9 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.1/14.9 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.4/14.9 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.8/14.9 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.2/14.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/14.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.9/14.9 MB 7.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.9 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/14.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.9/14.9 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 450.6/502.5 kB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 502.5/502.5 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 0.0/346.6 kB ? eta -:--:--\n",
      "   --------------------------------------  337.9/346.6 kB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 346.6/346.6 kB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "Successfully installed numpy-1.24.4 pandas-2.0.3 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 tzdata-2023.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7923329-5dbf-4c22-97be-970e4fa0b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e52f045-8939-4ce0-a7a3-b3ed04384359",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession  \u001b[38;5;66;03m# entry point for pyspark\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# instantiate spark instance\u001b[39;00m\n\u001b[0;32m      4\u001b[0m spark \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      5\u001b[0m     SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest eCommerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.executor.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4g\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession  # entry point for pyspark\n",
    "\n",
    "# instantiate spark instance\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Random Forest eCommerce\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dedf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../archive/2019-Nov.csv\"  # wherever path you saved the kaggle file to\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "df.printSchema()  # to see the schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00599c44",
   "metadata": {},
   "source": [
    "If you want to use Pandas to explore the dataset instead of Pyspark, you have to use the `action` functions, which then means there will be a network shuffle. For smaller dataset such as the Iris dataset which is about ~1KB this is no problem. The current dataset may be too large, and may throw an `OutOfMemory` error if you attempt to load the data into a Pandas dataframe. You should only take a few rows for exploratory analysis if you are more comfortable with Pandas. Otherwise, stick with native PySpark functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8dcd29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>event_time</th>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>2019-11-01 00:00:00 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:01 UTC</td>\n",
       "      <td>2019-11-01 00:00:02 UTC</td>\n",
       "      <td>2019-11-01 00:00:02 UTC</td>\n",
       "      <td>2019-11-01 00:00:02 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_type</th>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <td>1003461</td>\n",
       "      <td>5000088</td>\n",
       "      <td>17302664</td>\n",
       "      <td>3601530</td>\n",
       "      <td>1004775</td>\n",
       "      <td>1306894</td>\n",
       "      <td>1306421</td>\n",
       "      <td>15900065</td>\n",
       "      <td>12708937</td>\n",
       "      <td>1004258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>2053013566100866035</td>\n",
       "      <td>2053013553853497655</td>\n",
       "      <td>2053013563810775923</td>\n",
       "      <td>2053013555631882655</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>2053013558920217191</td>\n",
       "      <td>2053013558190408249</td>\n",
       "      <td>2053013553559896355</td>\n",
       "      <td>2053013555631882655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_code</th>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>appliances.sewing_machine</td>\n",
       "      <td>None</td>\n",
       "      <td>appliances.kitchen.washer</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>computers.notebook</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>electronics.smartphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>xiaomi</td>\n",
       "      <td>janome</td>\n",
       "      <td>creed</td>\n",
       "      <td>lg</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>hp</td>\n",
       "      <td>hp</td>\n",
       "      <td>rondell</td>\n",
       "      <td>michelin</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>489.07</td>\n",
       "      <td>293.65</td>\n",
       "      <td>28.31</td>\n",
       "      <td>712.87</td>\n",
       "      <td>183.27</td>\n",
       "      <td>360.09</td>\n",
       "      <td>514.56</td>\n",
       "      <td>30.86</td>\n",
       "      <td>72.72</td>\n",
       "      <td>732.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>520088904</td>\n",
       "      <td>530496790</td>\n",
       "      <td>561587266</td>\n",
       "      <td>518085591</td>\n",
       "      <td>558856683</td>\n",
       "      <td>520772685</td>\n",
       "      <td>514028527</td>\n",
       "      <td>518574284</td>\n",
       "      <td>532364121</td>\n",
       "      <td>532647354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_session</th>\n",
       "      <td>4d3b30da-a5e4-49df-b1a8-ba5943f1dd33</td>\n",
       "      <td>8e5f4f83-366c-4f70-860e-ca7417414283</td>\n",
       "      <td>755422e7-9040-477b-9bd2-6a6e8fd97387</td>\n",
       "      <td>3bfb58cd-7892-48cc-8020-2f17e6de6e7f</td>\n",
       "      <td>313628f1-68b8-460d-84f6-cec7a8796ef2</td>\n",
       "      <td>816a59f3-f5ae-4ccd-9b23-82aa8c23d33c</td>\n",
       "      <td>df8184cc-3694-4549-8c8c-6b5171877376</td>\n",
       "      <td>5e6ef132-4d7c-4730-8c7f-85aa4082588f</td>\n",
       "      <td>0a899268-31eb-46de-898d-09b2da950b24</td>\n",
       "      <td>d2d3d2c6-631d-489e-9fb5-06f340b85be0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "event_time                  2019-11-01 00:00:00 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1003461   \n",
       "category_id                     2053013555631882655   \n",
       "category_code                electronics.smartphone   \n",
       "brand                                        xiaomi   \n",
       "price                                        489.07   \n",
       "user_id                                   520088904   \n",
       "user_session   4d3b30da-a5e4-49df-b1a8-ba5943f1dd33   \n",
       "\n",
       "                                                  1  \\\n",
       "event_time                  2019-11-01 00:00:00 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  5000088   \n",
       "category_id                     2053013566100866035   \n",
       "category_code             appliances.sewing_machine   \n",
       "brand                                        janome   \n",
       "price                                        293.65   \n",
       "user_id                                   530496790   \n",
       "user_session   8e5f4f83-366c-4f70-860e-ca7417414283   \n",
       "\n",
       "                                                  2  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                 17302664   \n",
       "category_id                     2053013553853497655   \n",
       "category_code                                  None   \n",
       "brand                                         creed   \n",
       "price                                         28.31   \n",
       "user_id                                   561587266   \n",
       "user_session   755422e7-9040-477b-9bd2-6a6e8fd97387   \n",
       "\n",
       "                                                  3  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  3601530   \n",
       "category_id                     2053013563810775923   \n",
       "category_code             appliances.kitchen.washer   \n",
       "brand                                            lg   \n",
       "price                                        712.87   \n",
       "user_id                                   518085591   \n",
       "user_session   3bfb58cd-7892-48cc-8020-2f17e6de6e7f   \n",
       "\n",
       "                                                  4  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1004775   \n",
       "category_id                     2053013555631882655   \n",
       "category_code                electronics.smartphone   \n",
       "brand                                        xiaomi   \n",
       "price                                        183.27   \n",
       "user_id                                   558856683   \n",
       "user_session   313628f1-68b8-460d-84f6-cec7a8796ef2   \n",
       "\n",
       "                                                  5  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1306894   \n",
       "category_id                     2053013558920217191   \n",
       "category_code                    computers.notebook   \n",
       "brand                                            hp   \n",
       "price                                        360.09   \n",
       "user_id                                   520772685   \n",
       "user_session   816a59f3-f5ae-4ccd-9b23-82aa8c23d33c   \n",
       "\n",
       "                                                  6  \\\n",
       "event_time                  2019-11-01 00:00:01 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                  1306421   \n",
       "category_id                     2053013558920217191   \n",
       "category_code                    computers.notebook   \n",
       "brand                                            hp   \n",
       "price                                        514.56   \n",
       "user_id                                   514028527   \n",
       "user_session   df8184cc-3694-4549-8c8c-6b5171877376   \n",
       "\n",
       "                                                  7  \\\n",
       "event_time                  2019-11-01 00:00:02 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                 15900065   \n",
       "category_id                     2053013558190408249   \n",
       "category_code                                  None   \n",
       "brand                                       rondell   \n",
       "price                                         30.86   \n",
       "user_id                                   518574284   \n",
       "user_session   5e6ef132-4d7c-4730-8c7f-85aa4082588f   \n",
       "\n",
       "                                                  8  \\\n",
       "event_time                  2019-11-01 00:00:02 UTC   \n",
       "event_type                                     view   \n",
       "product_id                                 12708937   \n",
       "category_id                     2053013553559896355   \n",
       "category_code                                  None   \n",
       "brand                                      michelin   \n",
       "price                                         72.72   \n",
       "user_id                                   532364121   \n",
       "user_session   0a899268-31eb-46de-898d-09b2da950b24   \n",
       "\n",
       "                                                  9  \n",
       "event_time                  2019-11-01 00:00:02 UTC  \n",
       "event_type                                     view  \n",
       "product_id                                  1004258  \n",
       "category_id                     2053013555631882655  \n",
       "category_code                electronics.smartphone  \n",
       "brand                                         apple  \n",
       "price                                        732.07  \n",
       "user_id                                   532647354  \n",
       "user_session   d2d3d2c6-631d-489e-9fb5-06f340b85be0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.take(10), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4be40f",
   "metadata": {},
   "source": [
    "### Know your Customers\n",
    "\n",
    "How many unique customers visit the site?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b065821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT user_id)|\n",
      "+-----------------------+\n",
      "|                3696117|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using native pyspark\n",
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df.select(countDistinct(\"user_id\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3802c",
   "metadata": {},
   "source": [
    "Did you notice the spark progress bar when you triggered the `action` function? The `show()` function is the `action` function which means the lazy evaluation of Spark was triggered and completed a certain job. `read.csv` should have been another job. If you go to `localhost:4040` you should be able to see 2 completed jobs under the `Jobs` tab, which are `csv` and `showString`. While a heavy job is getting executed, you can take a look at the `Executors` tab to examine the executors completing the tasks in parellel. Now, you may not see if we run this on a local machine, but this behavior should definitely be visible if you're on a cloud system, such as EMR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76339535",
   "metadata": {},
   "source": [
    "### (Optional) Visitors Daily Trend\n",
    "\n",
    "Does traffic flunctuate by date? Try using the event_time to see traffic, and draw the plots for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998938b5-1b63-45c2-ba6a-dbbd6b05c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event_time you should use a window and groupby a time period\n",
    "from pyspark.sql.functions import window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352dadc9",
   "metadata": {},
   "source": [
    "Question: You would still like to see the cart abandonment rate using the dataset. What relevant features can we use for modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeea5b9",
   "metadata": {},
   "source": [
    "Now, you will start building the model. Add the columns you would like to use for predictor features in the model to the `feature_cols` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55df7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = []  # columns you'd like to use\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c53a7",
   "metadata": {},
   "source": [
    "To use a string column, you can use the `StringIndexer` to encode the column. Update the `inputCol` keyword argument so that you can encode the target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "labeler = StringIndexer(\n",
    "    inputCol=\"\", outputCol=\"encoded\"\n",
    ")  # what should we use for the inputCol here?\n",
    "df = labeler.fit(df).transform(df)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacb771",
   "metadata": {},
   "source": [
    "Now build the train/test dataset with a 70/30 `randomSplit` and a random seed set to 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8be79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit()\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d4f7a-580d-4890-af7a-47675b158d3a",
   "metadata": {},
   "source": [
    "Next you need to add in the name of the feature column and the name of the `labelCol` you previously encoded for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"\", labelCol=\"\")\n",
    "model = rf.fit(train)\n",
    "predictions = model.transform(test)\n",
    "# what goes in the select() function?\n",
    "predictions.select().show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdadc1f",
   "metadata": {},
   "source": [
    "Once the job execution is done, evaluate the model's performance. Add in the `labelCol` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94817fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %s\" % (accuracy))\n",
    "print(\"Test Error = %s\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99d0a4",
   "metadata": {},
   "source": [
    "### Extra: Use the confusion matrix to see the other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "preds_and_labels = (\n",
    "    predictions.select([\"prediction\", \"encoded\"])\n",
    "    .withColumn(\"encoded\", F.col(\"encoded\").cast(FloatType()))\n",
    "    .orderBy(\"prediction\")\n",
    ")\n",
    "preds_and_labels = preds_and_labels.select([\"prediction\", \"encoded\"])\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d042f7e-d5da-4c3e-afd1-5935929fef27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
